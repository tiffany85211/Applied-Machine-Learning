{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Machine Learning CS5785 Homework 1\n",
    "## Programming Exercise 2 - Predicting House Prices\n",
    "\n",
    "\n",
    "Group: Ting-Wei Chiang (tc695), Jeremy Shaffer (jms995)\n",
    "\n",
    "Kaggle competition: https://www.kaggle.com/c/house-prices-advanced-regression-techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [12, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our first glance of data, we observed that: \n",
    "1. There are both numeric and categorical features.\n",
    "2. There are some missing values (NaNs) that need to be taken care of.\n",
    "3. Column `Id` should be excluded from features.\n",
    "4. Column `SalePrice` only exists in training data, and is approximately a 6-figure number.\n",
    "5. The dimension of training data is 81 while that of testing data is 80 because training data includes target variable `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1460, 81)\n",
      "Test data shape: (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print (\"Train data shape:\", train.shape)\n",
    "print (\"Test data shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For data preprocessing and feature engineering, we did the followings:\n",
    "1. Scaling Training Target: Log transform the skewed target variable by taking $log(SalePrice)$\n",
    "2. For Numeric Features: \n",
    "    1. Log transform the skewed features by taking $log(feature + 1)$\n",
    "    2. Missing data imputation: Replace the missing values with the median of the feature\n",
    "3. For Categorical Features: One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Scaling Training Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used `plt.hist()` to plot a histogram of `SalePrice`. From the first graph, we can see that the original distribution of `SalePrice` in training data is positively-skewed (right-skewed). \n",
    "As we are performing regression, we applied log transformation on the skewed variable to improve the linearity of the data. After log transformation, the histogram looks more like normal distribution, and the skewness value is closer to 0. Lastly, we stored the log-transformed training target in a new variable `y_train_all`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.SalePrice.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness for Saleprice = 1.8828757597682129\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness for log(Saleprice) = 0.12133506220520406\n"
     ]
    }
   ],
   "source": [
    "# Plot histograms\n",
    "\n",
    "# original distribution\n",
    "plt.hist(train.SalePrice)\n",
    "plt.show()\n",
    "print (\"Skewness for Saleprice =\", train.SalePrice.skew())\n",
    "# distribution after log transformation\n",
    "plt.hist(np.log(train.SalePrice))    \n",
    "plt.show()\n",
    "print (\"Skewness for log(Saleprice) =\", np.log(train.SalePrice).skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform training target\n",
    "\n",
    "y_train_all = np.log(train.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering for Numeric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the same process of feature engineering needs to be performed on both training and testing data, we combined them first to variable `X`, and later separated them back to `X_train_all` and `X_test` according to whether they have values for column `SalePrice` or not. \n",
    "\n",
    "We dropped the column `Id` because it does not convey any meaning to the model and should be excluded from the set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([train, test], ignore_index=True, sort=False)\n",
    "X = X.drop(columns = ['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check correlation between all features and target\n",
    "\n",
    "# numeric_features = train.select_dtypes(include=[np.number])\n",
    "# corr = numeric_features.corr()\n",
    "# print (corr['SalePrice'].sort_values(ascending=False)[1:6])\n",
    "# print (corr['SalePrice'].sort_values(ascending=True)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform skewed numeric features\n",
    "\n",
    "numeric_features = X.dtypes[X.dtypes != \"object\"].index\n",
    "skewed_features = X[numeric_features].apply(lambda x: x.skew()) #compute skewness\n",
    "skewed_features = skewed_features[(skewed_features > 0.75) | (skewed_features < -0.75)]\n",
    "skewed_features = skewed_features.index\n",
    "print(skewed_features)\n",
    "X[skewed_features] = np.log1p(X[skewed_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Data Imputation: median\n",
    "\n",
    "X_target = X.SalePrice\n",
    "X = X.drop(columns = ['SalePrice']).fillna(X.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "\n",
    "train_null_count = X.isnull().sum()    # can also use df.isna()\n",
    "train_null_count[train_null_count > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, X_target], axis=1)\n",
    "X_train_all = X.loc[X['SalePrice'].notna()]\n",
    "X_test = X.loc[X['SalePrice'].isna()]\n",
    "# Drop columns\n",
    "X_train_all = X_train.drop(columns = ['SalePrice'])\n",
    "X_test = X_test.drop(columns = ['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_all.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear model: Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_all, y_train_all, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "linear_model = lr.fit(X_train, y_train)\n",
    "print (\"R square for Linear Regression =\", linear_model.score(X_val, y_val))\n",
    "print ('RMSE for Linear Regression =', mean_squared_error(y_val, linear_model.predict(X_val), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model using all training data\n",
    "\n",
    "linear_model = LinearRegression().fit(X_train_all, y_train_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Regularized Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L1 Regularization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.arange(-3.8, 0, 0.1)\n",
    "alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose alpha by min RMSE on validation set\n",
    "\n",
    "model_list = []\n",
    "rsquare_list = []\n",
    "rmse_list = []\n",
    "for alpha in alphas:\n",
    "    model = Lasso(alpha=alpha)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    model_list.append(model)\n",
    "    pred = model.predict(X_val)\n",
    "    rsquare_list.append(model.score(X_val, y_val))\n",
    "    rmse_list.append(mean_squared_error(y_val, pred, squared=False))\n",
    "print(\"R square for Lasso Regression =\", rsquare_list[rmse_list.index(min(rmse_list))])\n",
    "print(\"RMSE for Lasso Regression =\", min(rmse_list))\n",
    "print(\"when alpha =\", alphas[rmse_list.index(min(rmse_list))])\n",
    "\n",
    "lasso_model_2 = model_list[rmse_list.index(min(rmse_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose alpha by cross validation on training set\n",
    "\n",
    "lasso_model = LassoCV(alphas = alphas, cv=5).fit(X_train_all, y_train_all)\n",
    "print (\"R square for Lasso Regression =\", lasso_model.score(X_val, y_val))\n",
    "print (\"RMSE for Lasso Regression =\", mean_squared_error(y_val, lasso_model.predict(X_val), squared=False))\n",
    "print (\"when alpha =\", lasso_model.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.Series(lasso_model.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "imp_coef = pd.concat([coef.sort_values().head(10),\n",
    "                     coef.sort_values().tail(10)])\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Lasso Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L2 Regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 10**np.arange(-2, 2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose alpha by min RMSE on validation set\n",
    "\n",
    "model_list = []\n",
    "rsquare_list = []\n",
    "rmse_list = []\n",
    "for alpha in alphas:\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    model_list.append(model)\n",
    "    pred = model.predict(X_val)\n",
    "    rsquare_list.append(model.score(X_val, y_val))\n",
    "    rmse_list.append(mean_squared_error(y_val, pred, squared=False))\n",
    "print(\"R square for Ridge Regression =\", rsquare_list[rmse_list.index(min(rmse_list))])\n",
    "print(\"RMSE for Ridge Regression =\", min(rmse_list))\n",
    "print(\"when alpha =\", alphas[rmse_list.index(min(rmse_list))])\n",
    "\n",
    "ridge_model_2 = model_list[rmse_list.index(min(rmse_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose alpha by cross validation on training set\n",
    "\n",
    "ridge_model = RidgeCV(alphas = alphas, cv=5).fit(X_train_all, y_train_all)\n",
    "print (\"R square for Ridge Regression =\", ridge_model.score(X_val, y_val))\n",
    "print (\"RMSE for Ridge Regression =\", mean_squared_error(y_val, ridge_model.predict(X_val), squared=False))\n",
    "print (\"when alpha =\", ridge_model.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_linear = np.exp(linear_model.predict(X_test))\n",
    "pred_lasso = np.exp(lasso_model.predict(X_test))\n",
    "pred_ridge = np.exp(ridge_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['Id'] = test.Id\n",
    "res['SalePrice'] = pred_linear\n",
    "res.to_csv('res_linear_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['Id'] = test.Id\n",
    "res['SalePrice'] = pred_lasso\n",
    "res.to_csv('res_lasso_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['Id'] = test.Id\n",
    "res['SalePrice'] = pred_ridge\n",
    "res.to_csv('res_ridge_all.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
